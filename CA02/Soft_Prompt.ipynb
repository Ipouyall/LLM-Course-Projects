{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALnEUrLq1-kp"
      },
      "source": [
        "## CA 2, LLMs Spring 2024\n",
        "\n",
        "- **Name:**\n",
        "- **Student ID:**\n",
        "\n",
        "---\n",
        "#### Your submission should be named using the following format: `CA2_LASTNAME_STUDENTID_soft_prompt.ipynb`.\n",
        "\n",
        "- There is no penalty for using AI assistance on this homework as long as you fully disclose it in the final cell of this notebook (this includes storing any prompts that you feed to large language models). That said, anyone caught using AI assistance without proper disclosure will receive a zero on the assignment (we have several automatic tools to detect such cases). We're literally allowing you to use it with no limitations, so there is no reason to lie!\n",
        "\n",
        "---\n",
        "\n",
        "##### *Academic honesty*\n",
        "\n",
        "- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your notebook. If you turn in correct answers on your notebook without code that actually generates those answers, we will consider this a serious case of cheating.\n",
        "\n",
        "- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n",
        "\n",
        "---\n",
        "\n",
        "If you have any further questions or concerns, contact the TA via email:\n",
        "mohammad136631@gmail.com\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfrgatGB3Aac"
      },
      "source": [
        "# What are Soft prompts?\n",
        "Soft prompts are learnable tensors concatenated with the input embeddings that can be optimized to a dataset; the downside is that they aren’t human readable because you aren’t matching these “virtual tokens” to the embeddings of a real word.\n",
        "<br>\n",
        "<div>\n",
        "<img src=\"https://www.researchgate.net/publication/366062946/figure/fig1/AS:11431281105340756@1670383256990/The-comparison-between-the-previous-T5-prompt-tuning-method-part-a-and-the-introduced.jpg\"/>\n",
        "</div>\n",
        "\n",
        "Read More:\n",
        "<br>[Youtube : PEFT and Soft Prompt](https://www.youtube.com/watch?v=8uy_WII76L0)\n",
        "<br>[Paper: The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691.pdf)\n",
        "https://arxiv.org/pdf/2101.00190.pdf\n",
        "<br>[Paper: Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLaYIRN4X7cC"
      },
      "source": [
        "# Part 1 (20 Points)\n",
        "Before diving into the practical applications, let's first ensure your foundational knowledge is solid. Please answer the following questions.\n",
        "\n",
        "\n",
        "**A) Compare and contrast model tuning and prompt tuning in terms of their effectiveness for specific downstream tasks. (5 Points)**\n",
        "\n",
        "**B) Explore the challenges associated with interpreting soft prompts in the continuous embedding space and propose potential solutions. (5 Points)**\n",
        "\n",
        "**C) What is the effect of initializing prompts randomly versus initializing them from the vocabulary, and how does this impact the performance of prompt tuning? (5 Points)**\n",
        "\n",
        "**D) How is the optimization process in the prefix tuning(<br>[Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190.pdf)) and Why did they use this technique? (5 Points)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQMgi75DV-bo"
      },
      "source": [
        "# Part 2 (35 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3gjmZROpLP5"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG_yY6ep9C7S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import transformers\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_UcfBmLpRiJ"
      },
      "source": [
        "## Model Selection & Constants\n",
        "We will use `bert-fa-base-uncased` as our base model from Hugging Face ([HF_Link](https://huggingface.co/HooshvareLab/bert-fa-base-uncased)). For our tuning, we intend to utilize 20 soft prompt tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV2aP8bwV-z5"
      },
      "outputs": [],
      "source": [
        "class CONFIG:\n",
        "    seed = 42\n",
        "    max_len = 128\n",
        "    train_batch = 16\n",
        "    valid_batch = 32\n",
        "    epochs = 10\n",
        "    n_tokens=20\n",
        "    learning_rate = 0.01\n",
        "    model_name = 'HooshvareLab/bert-fa-base-uncased'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T0asPslpkSh"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset contains around 7000 Persian sentences and their corresponding polarity, and have been manually classified into 5 categories (i.e. Angry)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xpsgvYumvNa"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2JmHJ2wpoaX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "file_path = \"\"\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmviyjCrz6mi"
      },
      "source": [
        "### Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PITqCGDx0McE"
      },
      "outputs": [],
      "source": [
        "%pip install -U clean-text[gpl]\n",
        "%pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0Nlfm0qE_1P"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from cleantext import clean\n",
        "from hazm import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4CFqPaV0Pqp"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def cleanhtml(raw_html):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', raw_html)\n",
        "    return cleantext\n",
        "\n",
        "def cleaning(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    # regular cleaning\n",
        "    text = clean(text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=False,\n",
        "        lower=True,\n",
        "        no_line_breaks=True,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_numbers=False,\n",
        "        no_digits=False,\n",
        "        no_currency_symbols=True,\n",
        "        no_punct=False,\n",
        "        replace_with_url=\"\",\n",
        "        replace_with_email=\"\",\n",
        "        replace_with_phone_number=\"\",\n",
        "        replace_with_number=\"\",\n",
        "        replace_with_digit=\"0\",\n",
        "        replace_with_currency_symbol=\"\",\n",
        "    )\n",
        "\n",
        "    text = cleanhtml(text)\n",
        "\n",
        "    # normalizing\n",
        "    #normalizer = hazm.Normalizer()\n",
        "    #text = normalizer.normalize(text)\n",
        "\n",
        "    wierd_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u'\\U00010000-\\U0010ffff'\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\u3030\"\n",
        "        u\"\\ufe0f\"\n",
        "        u\"\\u2069\"\n",
        "        u\"\\u2066\"\n",
        "        u\"\\u2068\"\n",
        "        u\"\\u2067\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    text = wierd_pattern.sub(r'', text)\n",
        "\n",
        "    # removing extra spaces, hashtags\n",
        "    text = re.sub(\"#\", \"\", text)\n",
        "    text = re.sub(\"\\s+\", \" \", text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_5ZyotA0cxw"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "def parallel_apply_with_progress(df, func, n_workers=4):\n",
        "    with ThreadPoolExecutor(max_workers=n_workers) as executor, tqdm(total=len(df)) as pbar:\n",
        "        def update(*args):\n",
        "            pbar.update()\n",
        "\n",
        "        results = []\n",
        "        for result in executor.map(func, df['text']):\n",
        "            results.append(result)\n",
        "            update()\n",
        "\n",
        "        df['text'] = pd.Series(results)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APUjLG3E0qxK",
        "outputId": "504a5776-9d44-4848-df37-5ac0ac46ae70"
      },
      "outputs": [],
      "source": [
        "df = parallel_apply_with_progress(df, cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2tZk2fBSwJL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values,\n",
        "                                                  df.label.values,\n",
        "                                                  test_size=0.15,\n",
        "                                                  random_state=42,\n",
        "                                                  stratify=df.label.values)\n",
        "\n",
        "train_df = df.loc[X_train]\n",
        "validation_df = df.loc[X_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GTgl8-RV926",
        "outputId": "cf4793be-7fc7-4110-ad22-db2700172956"
      },
      "outputs": [],
      "source": [
        "possible_labels = df.label.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgTnO4ctWKqo"
      },
      "outputs": [],
      "source": [
        "train_df['label'] = train_df.label.replace(label_dict)\n",
        "validation_df['label'] = validation_df.label.replace(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqIWHJ9XMiOr"
      },
      "source": [
        "### Create Dataset Class (5 Points)\n",
        "In this step we will getting our dataset ready for training.\n",
        "\n",
        "In this part we will define BERT-based dataset class for text classification, with configuration parameters. It preprocesses text data and tokenizes it using the BERT tokenizer.\n",
        "\n",
        "\n",
        "Complete the preprocessing step in the __getitem__ method by adding padding tokens to 'input_ids' and 'attention_mask',\n",
        "The count of this pad tokens is the same as `n_tokens`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyS6DyeZ75bZ"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self,df):\n",
        "        self.text = df['text'].values\n",
        "        self.labels = df['label'].values\n",
        "        self.all_labels = [0, 1, 2, 3, 4]\n",
        "        self.max_len = CONFIG.max_len\n",
        "        self.tokenizer = CONFIG.tokenizer\n",
        "        self.n_tokens=CONFIG.n_tokens\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.text[index]\n",
        "        text = ' '.join(text.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        ######### Your code begins #########\n",
        "        inputs['input_ids'] =\n",
        "        inputs['attention_mask'] =\n",
        "        ######### Your code ends ###########\n",
        "\n",
        "        labels = self.labels[index]\n",
        "        label_dict = {label: (label == labels) for label in self.all_labels}\n",
        "        labels_tensor = torch.tensor([float(label_dict[label]) for label in self.all_labels])\n",
        "        return {\n",
        "            'ids': inputs['input_ids'],\n",
        "            'mask': inputs['attention_mask'],\n",
        "            'label': labels_tensor\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf8AYo8cFiud"
      },
      "outputs": [],
      "source": [
        "train_dataset = BERTDataset(train_df)\n",
        "validation_dataset = BERTDataset(validation_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSWkTORNcxvx"
      },
      "source": [
        "## Define Prompt Embedding Layer (15 Points)\n",
        "In this part we will define our prompt layer in `PROMPTEmbedding` module.\n",
        "\n",
        "\n",
        "<font color='#73FF73'><b>You have to complete</b></font> `initialize_embedding` and  `forward` <font color='#73FF73'><b>functions.</b></font>\n",
        "\n",
        "In `initialize_embedding` function initialize the learned embeddings based on whether they should be initialized from the vocabulary or randomly within the specified range.\n",
        "\n",
        "In `forward` function, modify the input_embedding to extract the relevant part based on n_tokens.\n",
        "\n",
        "Repeat the learned_embedding to match the size of input_embedding.\n",
        "\n",
        "Concatenate the learned_embedding and input_embedding properly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tqAU4Ubj2t8"
      },
      "outputs": [],
      "source": [
        "class PROMPTEmbedding(nn.Module):\n",
        "    def __init__(self,\n",
        "                emb_layer: nn.Embedding,\n",
        "                n_tokens: int = 20,\n",
        "                random_range: float = 0.5,\n",
        "                initialize_from_vocab: bool = True):\n",
        "\n",
        "      super(PROMPTEmbedding, self).__init__()\n",
        "      self.emb_layer = emb_layer\n",
        "      self.n_tokens = n_tokens\n",
        "      self.learned_embedding = nn.parameter.Parameter(self.initialize_embedding(emb_layer,\n",
        "                                                                               n_tokens,\n",
        "                                                                               random_range,\n",
        "                                                                               initialize_from_vocab))\n",
        "\n",
        "    def initialize_embedding(self,\n",
        "                             emb_layer: nn.Embedding,\n",
        "                             n_tokens: int = 20,\n",
        "                             random_range: float = 0.5,\n",
        "                             initialize_from_vocab: bool = True):\n",
        "\n",
        "      if initialize_from_vocab:\n",
        "        ######### Your code begins #########\n",
        "        vocab_emb =\n",
        "\n",
        "        return vocab_emb\n",
        "\n",
        "      else:\n",
        "        random_emb =\n",
        "        ######### Your code ends ###########\n",
        "      return random_emb\n",
        "\n",
        "\n",
        "    def forward(self, tokens):\n",
        "      ######### Your code begins #########\n",
        "      input_embedding =\n",
        "      learned_embedding =\n",
        "      joined_embedding =\n",
        "      ######### Your code ends ###########\n",
        "      return joined_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhES_23bDfXZ"
      },
      "source": [
        "## Replace model's embedding layer with our layer (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AMhjuooOQKA"
      },
      "outputs": [],
      "source": [
        "# Define your BERT model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(CONFIG.model_name, num_labels=5, output_attentions = False,\n",
        "                                                           output_hidden_states = False).to(CONFIG.device)\n",
        "######### Your code begins #########\n",
        "\n",
        "######### Your code ends ###########\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wlsc2meajrn"
      },
      "source": [
        "## Freezing Model Parameters (5 points)\n",
        "In this part we will freeze entire model except `learned_embedding`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CCq8Z1lajGC"
      },
      "outputs": [],
      "source": [
        "######### Your code begins #########\n",
        "\n",
        "######### Your code ends ###########"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8ud-O_Rrptq"
      },
      "source": [
        "## Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IckuDmDWRye"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=CONFIG.learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17S9KFKM1jgP"
      },
      "source": [
        "## Training & Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZsfsyKAY2yu"
      },
      "source": [
        "### Define dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVRa2SLDWUM9"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch,\n",
        "                              num_workers=2, shuffle=True, pin_memory=True)\n",
        "\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=CONFIG.valid_batch,\n",
        "                              num_workers=2, shuffle=True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0Sj5pT6ZDbz"
      },
      "source": [
        "### Define evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f-OVsQ5_War"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bqs9Hxi9yjz"
      },
      "outputs": [],
      "source": [
        "def evaluate(val_dataloader):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "\n",
        "\n",
        "        inputs = {'input_ids':      batch['ids'].to(CONFIG.device),\n",
        "                  'attention_mask': batch['mask'].to(CONFIG.device),\n",
        "                  'labels':         batch['label'].to(CONFIG.device),\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[\"loss\"]\n",
        "        logits = outputs[\"logits\"]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "\n",
        "    loss_val_avg = loss_val_total/len(val_dataloader)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    return loss_val_avg, predictions, true_vals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjO1TwDSZMWH"
      },
      "source": [
        "### Define trainng loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjXZ7oB_1jGv"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_dataloader, val_dataloader):\n",
        "\n",
        "    epochs = CONFIG.epochs\n",
        "\n",
        "    for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      loss_train_total = 0\n",
        "\n",
        "      progress_bar = tqdm(train_loader, desc='Epoch {:1d}'.format(epoch), leave=False, disable=True)\n",
        "\n",
        "      for batch in progress_bar:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs = {'input_ids':      batch['ids'].to(CONFIG.device),\n",
        "                  'attention_mask': batch['mask'].to(CONFIG.device),\n",
        "                  'labels':         batch['label'].to(CONFIG.device),\n",
        "                }\n",
        "\n",
        "        output = model(**inputs)\n",
        "\n",
        "        loss = output[\"loss\"]\n",
        "        loss_train_total += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "\n",
        "      tqdm.write(f'\\nEpoch {epoch}')\n",
        "      loss_train_avg = loss_train_total/len(train_loader)\n",
        "      tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "\n",
        "      val_loss, predictions, true_vals = evaluate(val_dataloader)\n",
        "      val_f1 = f1_score_func(predictions, true_vals)\n",
        "      tqdm.write(f'Validation loss: {val_loss}')\n",
        "      tqdm.write(f'F1 Score (Weighted): {val_f1}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaTI1yeyZW1i"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--yqi1tp1jCv"
      },
      "outputs": [],
      "source": [
        "train(model=model, optimizer=optimizer, train_dataloader=train_loader, val_dataloader=validation_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_3FYFfIUKeE"
      },
      "source": [
        "## Using OpenDelta library (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yp3_9J0wUBxb"
      },
      "outputs": [],
      "source": [
        "!pip install opendelta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pOwAdIRUIKh"
      },
      "source": [
        "Use `OpenDelta` library to do the same thing. [link](https://opendelta.readthedocs.io/en/latest/modules/deltas.html)\n",
        "\n",
        "For hyperparameters, test with `N_SOFT_PROMPT_TOKENS=10` and `N_SOFT_PROMPT_TOKENS=20` and report them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiNnIlRlUFyS"
      },
      "outputs": [],
      "source": [
        "######### Your code begins #########\n",
        "model ="
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "n3gjmZROpLP5",
        "O_UcfBmLpRiJ",
        "2T0asPslpkSh",
        "7xpsgvYumvNa",
        "qmviyjCrz6mi",
        "wqIWHJ9XMiOr",
        "LSWkTORNcxvx",
        "lhES_23bDfXZ",
        "7Wlsc2meajrn",
        "T8ud-O_Rrptq",
        "17S9KFKM1jgP",
        "DZsfsyKAY2yu",
        "C0Sj5pT6ZDbz",
        "zjO1TwDSZMWH",
        "VaTI1yeyZW1i",
        "O_3FYFfIUKeE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
